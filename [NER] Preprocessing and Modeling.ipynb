{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efc1778a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T08:25:55.521847Z",
     "start_time": "2022-01-26T08:25:40.374289Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from tensorflow.keras import Sequential, Model, Input\n",
    "from tensorflow.keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional, Reshape, Concatenate, Activation\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from transformers import TFAutoModel\n",
    "from tensorflow.keras import backend as K\n",
    "from focal_loss import sparse_categorical_focal_loss\n",
    "from transformers import AutoModel\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from keras_contrib.layers import CRF\n",
    "# import tensorflow_hub as hub\n",
    "# import tensorflow_text as text\n",
    "import pythainlp\n",
    "import spacy_thai\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import re\n",
    "import string\n",
    "import os\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d432ecb1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T08:25:56.183501Z",
     "start_time": "2022-01-26T08:25:56.122330Z"
    }
   },
   "outputs": [],
   "source": [
    "def read_raw_text(filename):\n",
    "    \n",
    "    with open(filename, 'r', encoding = 'utf-8') as file:\n",
    "        \n",
    "        document = file.read()\n",
    "        \n",
    "    return document\n",
    "\n",
    "def read_ann_file(PATH, filename): #filename e.g. 01_nut.a/xxaa.ann\n",
    "    \n",
    "    PATH = PATH\n",
    "    \n",
    "    document = read_raw_text(PATH + filename[:-4] + '.txt')\n",
    "    df = pd.read_csv(PATH + filename, sep='^([^\\s]*)\\s', engine='python', header=None).drop(0, axis=1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    token_df = df[df[1].str.contains('T')]\n",
    "    \n",
    "    list_tokens = []\n",
    "    \n",
    "    seek = 0\n",
    "    \n",
    "    for index, row in token_df.iterrows():\n",
    "        \n",
    "        text = re.findall('\\t.*', row[2])[0][1:]\n",
    "        entityLabel, start, end = re.findall('.*\\t', row[2])[0][:-1].split(' ')\n",
    "        start, end = int(start), int(end)\n",
    "        \n",
    "        if seek == start:\n",
    "            res = [document[start:end], start, end, entityLabel]\n",
    "            list_tokens.append(res)\n",
    "            \n",
    "        else:\n",
    "#             print(seek, start)\n",
    "            res = [document[seek:start], seek, start, 'O']\n",
    "            list_tokens.append(res)\n",
    "            \n",
    "            res = [document[start:end], start, end, entityLabel]\n",
    "            list_tokens.append(res)\n",
    "            \n",
    "        seek = end\n",
    "    \n",
    "    \n",
    "    result_text = ''\n",
    "    \n",
    "    for t, start, end, ent in list_tokens:\n",
    "        text = f'[{ent}]{t}[/{ent}]'\n",
    "        result_text += text\n",
    "        \n",
    "    \n",
    "    return result_text, list_tokens\n",
    "\n",
    "def tokenize(text):\n",
    "    \n",
    "    nlp = spacy_thai.load()\n",
    "    pattern = r'\\[(.*?)\\](.*?)\\[\\/(.*?)\\]'\n",
    "    tokenizer = RegexpTokenizer(pattern)\n",
    "    \n",
    "    \n",
    "    text = re.sub(r'([ก-๏a-zA-Z\\(\\)\\.\\s0-9\\-]*)(?=\\[\\w+\\])', r'[O]\\1[/O]', text)\n",
    "    text = re.sub(r'([ก-๏a-zA-Z\\(\\)\\.\\s0-9\\-]+)$', r'[O]\\1[/O]', text)\n",
    "    text = re.sub(r'\\[O\\](\\s)*?\\[\\/O\\]', '', text)\n",
    "    t = tokenizer.tokenize(text)\n",
    "    \n",
    "    result = []\n",
    "    text_list_ = []\n",
    "    \n",
    "    for i in t:\n",
    "        \n",
    "            if i[0] == i[2]:\n",
    "                doc = pythainlp.syllable_tokenize(i[1])\n",
    "                token_texts = []\n",
    "\n",
    "                # doc = nlp('สวัสดีค้าบ ท่านผู้เจริญ')\n",
    "                for token in doc:\n",
    "                    token_texts.append(token)\n",
    "#                     if token.whitespace_:  # filter out empty strings\n",
    "#                         token_texts.append(token.whitespace_)\n",
    "                \n",
    "\n",
    "                if i[0] == 'O' :\n",
    "                    for r in range(len(token_texts)):\n",
    "                        result.append((token_texts[r],  i[0]))\n",
    "                  # words.append(r)\n",
    "                else:\n",
    "                    for r in range(len(token_texts)):\n",
    "        \n",
    "                        if r == 0:\n",
    "                            result.append((token_texts[r], 'B-' + i[0]))\n",
    "\n",
    "                        else:\n",
    "                            result.append((token_texts[r], 'I-' + i[0]))\n",
    "\n",
    "    text_list_.append(result)\n",
    "\n",
    "    words = []\n",
    "    tags = []\n",
    "    original_text = []\n",
    "    poss = []\n",
    "    contain_digit = []\n",
    "    contain_punc = []\n",
    "    contain_vowel = []\n",
    "\n",
    "    thai_vowel = 'ะาิีุุึืโเแัำไใฤๅฦ'\n",
    "\n",
    "    def check_condition(condition):\n",
    "\n",
    "        if condition:\n",
    "            return 'True'\n",
    "        else:\n",
    "            return 'False'\n",
    "\n",
    "    for text in text_list_:\n",
    "        w = []\n",
    "        t = []\n",
    "        o = ''\n",
    "        p = []\n",
    "        digit = []\n",
    "        punc = []\n",
    "        vowel = []\n",
    "        for word in text:\n",
    "            w.append(word[0])\n",
    "            t.append(word[1])\n",
    "    #         p.append(pythainlp.tag.pos_tag(word[0]))\n",
    "            o += word[0]\n",
    "            digit.append(check_condition(any(char.isdigit() for char in word[0])))\n",
    "            punc.append(check_condition(any(p in word[0] for p in punctuation)))\n",
    "            vowel.append(check_condition(any(p in word[0] for p in thai_vowel)))\n",
    "\n",
    "        words.append(w)\n",
    "        tags.append(t)\n",
    "        contain_digit.append(digit)\n",
    "        contain_punc.append(punc)\n",
    "        contain_vowel.append(vowel)\n",
    "    #     poss.append(p)\n",
    "        original_text.append(o)\n",
    "\n",
    "        \n",
    "#     dff = pd.DataFrame({'original_text' : original_text,\n",
    "#                         'words' : words,\n",
    "#     #                     'pos' : poss,\n",
    "#                         'contain_digit' : contain_digit,\n",
    "#                         'contain_punc' : contain_punc,\n",
    "#                         'contain_vowel' : contain_vowel,\n",
    "#                         'tags' : tags})\n",
    "\n",
    "    \n",
    "        \n",
    "    return words, tags, original_text, contain_digit, contain_punc, contain_vowel\n",
    "\n",
    "def read_all_file(PATH):\n",
    "    \n",
    "    PATH = PATH\n",
    "    assignee_folder_list = os.listdir(PATH)[3:3+15]\n",
    "\n",
    "    result = {'original_text' : [],\n",
    "              'words' : [],\n",
    "              'tags' : [],\n",
    "              'contain_digit' : [],\n",
    "              'contain_punc' : [],\n",
    "              'contain_vowel' : []}\n",
    "    for assignee_folder in assignee_folder_list:\n",
    "        text_folder_list = sorted(os.listdir(PATH + assignee_folder))\n",
    "        text_folder_list = [i for i in text_folder_list if i[-3:] in ['ann', 'txt']]\n",
    "        text_folder_list = set(map(lambda x : x[:-4], text_folder_list))\n",
    "        \n",
    "        \n",
    "        for text_folder in text_folder_list:\n",
    "            \n",
    "            filename = assignee_folder + '/' + text_folder + '.ann'\n",
    "            \n",
    "            try:\n",
    "                text, list_tokens = read_ann_file(PATH, filename)\n",
    "                words, tags, original_text, contain_digit, contain_punc, contain_vowel = tokenize(text)\n",
    "                result['original_text'].append(original_text)\n",
    "                result['words'].append(words)\n",
    "                result['tags'].append(tags)\n",
    "                result['contain_digit'].append(contain_digit)\n",
    "                result['contain_punc'].append(contain_punc)\n",
    "                result['contain_vowel'].append(contain_vowel)\n",
    "            except:\n",
    "                print(filename)\n",
    "                \n",
    "    df = pd.DataFrame(result)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "433cd3b8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T08:25:56.261540Z",
     "start_time": "2022-01-26T08:25:56.214937Z"
    }
   },
   "outputs": [],
   "source": [
    "def return_train_test(df):\n",
    "    \n",
    "    df['pos'] = df['words'].apply(lambda x : [i[1] for i in pythainlp.tag.pos_tag(x)])\n",
    "    \n",
    "    max_len = max(df['words'].apply(lambda x: len(x)))\n",
    "    \n",
    "    train, test = train_test_split(df, random_state = 42, test_size = 0.2)\n",
    "    \n",
    "    word_set = sorted(set([i for sentence in train['words'] for i in sentence]))\n",
    "    pos_set = sorted(set([i for pos in train['pos'] for i in pos]))\n",
    "    tag_set = sorted(set([i for tag in train['tags'] for i in tag]))\n",
    "     \n",
    "    word2idx = dict([(v, k) for k, v in enumerate(word_set)])\n",
    "    pos2idx = dict([(v, k) for k, v in enumerate(pos_set)])\n",
    "    tag2idx = dict([(v, k) for k, v in enumerate(tag_set)])\n",
    "    digit2idx = {'True' : 1, 'False' : 0, '<PAD>' : 2}\n",
    "    punc2idx = {'True' : 1, 'False' : 0, '<PAD>' : 2}\n",
    "    vowel2idx = {'True' : 1, 'False' : 0, '<PAD>' : 2}\n",
    "    \n",
    "    word2idx['<UNK>'] = len(word2idx)\n",
    "    word2idx['<PAD>'] = len(word2idx)\n",
    "    pos2idx['<UNK>'] = len(pos2idx)\n",
    "    pos2idx['<PAD>'] = len(pos2idx)\n",
    "    tag2idx['<PAD>'] = len(tag2idx)\n",
    "    \n",
    "    train['words_idx'] = train['words'].apply(lambda x: [word2idx[i] for i in x])\n",
    "    train['pos_idx'] = train['pos'].apply(lambda x: [pos2idx[i] for i in x])\n",
    "    train['tags_idx'] = train['tags'].apply(lambda x: [tag2idx[i] for i in x])\n",
    "    train['contain_digit_idx'] = train['contain_digit'].apply(lambda x: [digit2idx[i] for i in x])\n",
    "    train['contain_punc_idx'] = train['contain_punc'].apply(lambda x: [punc2idx[i] for i in x])\n",
    "    train['contain_vowel_idx'] = train['contain_vowel'].apply(lambda x: [vowel2idx[i] for i in x])\n",
    "    \n",
    "    test_sent = []\n",
    "    test_pos = []\n",
    "    test_tag = []\n",
    "    \n",
    "    for sent in test['words']:\n",
    "        t = []\n",
    "        for i in sent:\n",
    "            try:\n",
    "                t.append(word2idx[i])\n",
    "            except:\n",
    "                t.append(word2idx['<UNK>'])\n",
    "                \n",
    "        test_sent.append(t)\n",
    "                \n",
    "    for sent in test['pos']:\n",
    "        t = []\n",
    "        for i in sent:\n",
    "            try:\n",
    "                t.append(pos2idx[i])\n",
    "            except:\n",
    "                t.append(pos2idx['<UNK>'])\n",
    "        \n",
    "        test_pos.append(t)\n",
    "                \n",
    "    for sent in test['tags']:\n",
    "        t = []\n",
    "        for i in sent:\n",
    "            \n",
    "            t.append(tag2idx[i])\n",
    "            \n",
    "                \n",
    "        test_tag.append(t)\n",
    "        \n",
    "    test['words_idx'] = test_sent\n",
    "    test['pos_idx'] = test_pos\n",
    "    test['tags_idx'] = test_tag\n",
    "    test['contain_digit_idx'] = test['contain_digit'].apply(lambda x: [digit2idx[i] for i in x])\n",
    "    test['contain_punc_idx'] = test['contain_punc'].apply(lambda x: [punc2idx[i] for i in x])\n",
    "    test['contain_vowel_idx'] = test['contain_vowel'].apply(lambda x: [vowel2idx[i] for i in x])\n",
    "    \n",
    "    mapping = {'tok2idx' : word2idx,\n",
    "               'pos2idx' : pos2idx,\n",
    "               'tag2idx' : tag2idx}\n",
    "    \n",
    "    return train, test, mapping, max_len\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a444f26f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T08:45:41.675672Z",
     "start_time": "2022-01-26T08:45:41.434384Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_text</th>\n",
       "      <th>words</th>\n",
       "      <th>tags</th>\n",
       "      <th>contain_digit</th>\n",
       "      <th>contain_punc</th>\n",
       "      <th>contain_vowel</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>วันนี้ (24 พ.ค.2564) พ.ต.อ.เอกภพ ตันประยูร ผกก...</td>\n",
       "      <td>[วัน, นี้,  , (, 24,  , พ.ค., 2564, ),  , พ.ต....</td>\n",
       "      <td>[O, O, O, O, B-DATE, I-DATE, I-DATE, I-DATE, O...</td>\n",
       "      <td>[False, False, False, False, True, False, Fals...</td>\n",
       "      <td>[False, False, False, True, False, False, True...</td>\n",
       "      <td>[True, True, False, False, False, False, False...</td>\n",
       "      <td>[NCMN, DDAC, PUNC, PUNC, DCNM, PUNC, CMTR, NCN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>เมื่อวันที่ 19 ม.ค.พล.ท.บุญยืน อินกว่าง แม่ทัพ...</td>\n",
       "      <td>[เมื่อ, วัน, ที่,  , 19,  , ม.ค., พล.ท., บุญ, ...</td>\n",
       "      <td>[O, O, O, O, B-DATE, I-DATE, I-DATE, B-PERSON,...</td>\n",
       "      <td>[False, False, False, False, True, False, Fals...</td>\n",
       "      <td>[False, False, False, False, False, False, Tru...</td>\n",
       "      <td>[True, True, True, False, False, False, False,...</td>\n",
       "      <td>[JSBR, NCMN, PREL, PUNC, DCNM, PUNC, CMTR, NCM...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>เมื่อวันที่ 9 ม.ค. พล.ต.ต.เอกราช ลิ้มสังกาศ9 ม...</td>\n",
       "      <td>[เมื่อ, วัน, ที่,  , 9,  , ม.ค.,  , พล.ต.ต., เ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, B-PERSON, I-PERSON, I...</td>\n",
       "      <td>[False, False, False, False, True, False, Fals...</td>\n",
       "      <td>[False, False, False, False, False, False, Tru...</td>\n",
       "      <td>[True, True, True, False, False, False, False,...</td>\n",
       "      <td>[JSBR, NCMN, PREL, PUNC, DCNM, PUNC, CMTR, PUN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ผู้สื่อข่าวรายงานว่า วันนี้ (23 พ.ย.) เมื่อเวล...</td>\n",
       "      <td>[ผู้, สื่อ, ข่าว, ราย, งาน, ว่า,  , วัน, นี้, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, B-DATE, I-DA...</td>\n",
       "      <td>[False, False, False, False, False, False, Fal...</td>\n",
       "      <td>[False, False, False, False, False, False, Fal...</td>\n",
       "      <td>[False, True, True, True, True, True, False, T...</td>\n",
       "      <td>[PPRS, VACT, NCMN, CNIT, NCMN, JSBR, PUNC, NCM...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>เมื่อวันที่ 8 กันยายน 2564 เมื่อเวลา 12.30 น.พ...</td>\n",
       "      <td>[เมื่อ, วัน, ที่,  , 8,  , กัน, ยา, ยน,  , 256...</td>\n",
       "      <td>[O, O, O, O, B-DATE, I-DATE, I-DATE, I-DATE, I...</td>\n",
       "      <td>[False, False, False, False, True, False, Fals...</td>\n",
       "      <td>[False, False, False, False, False, False, Fal...</td>\n",
       "      <td>[True, True, True, False, False, False, True, ...</td>\n",
       "      <td>[JSBR, NCMN, PREL, PUNC, DCNM, PUNC, ADVN, ADV...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1945</th>\n",
       "      <td>จากสอบถาม นายพูนศักดิ์ ปทุมสิทธิ์ อายุ 24 ปี น...</td>\n",
       "      <td>[จาก, สอบ, ถาม,  , นาย, พูน, ศักดิ์,  , ปทุม, ...</td>\n",
       "      <td>[O, O, O, O, B-PERSON, I-PERSON, I-PERSON, I-P...</td>\n",
       "      <td>[False, False, False, False, False, False, Fal...</td>\n",
       "      <td>[False, False, False, False, False, False, Fal...</td>\n",
       "      <td>[True, False, True, False, True, False, True, ...</td>\n",
       "      <td>[RPRE, NCMN, VACT, PUNC, NTTL, NPRP, NPRP, PUN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1946</th>\n",
       "      <td>2 หนุ่มใหญ่ ตั้งวงกินเหล้า ทะเลาะเรื่องบัตรคนจ...</td>\n",
       "      <td>[2,  , หนุ่ม, ใหญ่,  , ตั้ง, วง, กิน, เหล้า,  ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[True, False, False, False, False, False, Fals...</td>\n",
       "      <td>[False, False, False, False, False, False, Fal...</td>\n",
       "      <td>[False, False, True, True, False, True, False,...</td>\n",
       "      <td>[NLBL, PUNC, NCMN, VATT, PUNC, VACT, NCMN, VAC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1947</th>\n",
       "      <td>ที่เกิดเหตุพบศพ นายเสถียร ธรรมมาทอง อายุ 49 ปี...</td>\n",
       "      <td>[ที่, เกิด, เหตุ, พบ, ศพ,  , นาย, เสถียร,  , ธ...</td>\n",
       "      <td>[O, O, O, O, O, O, B-PERSON, I-PERSON, I-PERSO...</td>\n",
       "      <td>[False, False, False, False, False, False, Fal...</td>\n",
       "      <td>[False, False, False, False, False, False, Fal...</td>\n",
       "      <td>[True, True, True, False, False, False, True, ...</td>\n",
       "      <td>[PREL, VSTA, NCMN, VSTA, NPRP, PUNC, NTTL, NPR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1948</th>\n",
       "      <td>เมื่อเวลา 01.30 น. วันที่ 24 พ.ย. 64 ร.ต.อ.ธรา...</td>\n",
       "      <td>[เมื่อ, เว, ลา,  , 01.30,  , น.,  , วัน, ที่, ...</td>\n",
       "      <td>[O, O, O, O, B-TIME, I-TIME, I-TIME, O, O, O, ...</td>\n",
       "      <td>[False, False, False, False, True, False, Fals...</td>\n",
       "      <td>[False, False, False, False, True, False, True...</td>\n",
       "      <td>[True, True, True, False, False, False, False,...</td>\n",
       "      <td>[JSBR, NCMN, NCMN, PUNC, DCNM, PUNC, CMTR, PUN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1949</th>\n",
       "      <td>จากนั้นทั้งสองกลุ่มจึงมีปากเสียงกัน แล้วพากันอ...</td>\n",
       "      <td>[จาก, นั้น, ทั้ง, สอง, กลุ่ม, จึง, มี, ปาก, เส...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[False, False, False, False, False, False, Fal...</td>\n",
       "      <td>[False, False, False, False, False, False, Fal...</td>\n",
       "      <td>[True, True, True, False, True, True, True, Tr...</td>\n",
       "      <td>[RPRE, DDAC, DDBQ, DCNM, CLTV, XVBM, VSTA, NCM...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1950 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          original_text  \\\n",
       "0     วันนี้ (24 พ.ค.2564) พ.ต.อ.เอกภพ ตันประยูร ผกก...   \n",
       "1     เมื่อวันที่ 19 ม.ค.พล.ท.บุญยืน อินกว่าง แม่ทัพ...   \n",
       "2     เมื่อวันที่ 9 ม.ค. พล.ต.ต.เอกราช ลิ้มสังกาศ9 ม...   \n",
       "3     ผู้สื่อข่าวรายงานว่า วันนี้ (23 พ.ย.) เมื่อเวล...   \n",
       "4     เมื่อวันที่ 8 กันยายน 2564 เมื่อเวลา 12.30 น.พ...   \n",
       "...                                                 ...   \n",
       "1945  จากสอบถาม นายพูนศักดิ์ ปทุมสิทธิ์ อายุ 24 ปี น...   \n",
       "1946  2 หนุ่มใหญ่ ตั้งวงกินเหล้า ทะเลาะเรื่องบัตรคนจ...   \n",
       "1947  ที่เกิดเหตุพบศพ นายเสถียร ธรรมมาทอง อายุ 49 ปี...   \n",
       "1948  เมื่อเวลา 01.30 น. วันที่ 24 พ.ย. 64 ร.ต.อ.ธรา...   \n",
       "1949  จากนั้นทั้งสองกลุ่มจึงมีปากเสียงกัน แล้วพากันอ...   \n",
       "\n",
       "                                                  words  \\\n",
       "0     [วัน, นี้,  , (, 24,  , พ.ค., 2564, ),  , พ.ต....   \n",
       "1     [เมื่อ, วัน, ที่,  , 19,  , ม.ค., พล.ท., บุญ, ...   \n",
       "2     [เมื่อ, วัน, ที่,  , 9,  , ม.ค.,  , พล.ต.ต., เ...   \n",
       "3     [ผู้, สื่อ, ข่าว, ราย, งาน, ว่า,  , วัน, นี้, ...   \n",
       "4     [เมื่อ, วัน, ที่,  , 8,  , กัน, ยา, ยน,  , 256...   \n",
       "...                                                 ...   \n",
       "1945  [จาก, สอบ, ถาม,  , นาย, พูน, ศักดิ์,  , ปทุม, ...   \n",
       "1946  [2,  , หนุ่ม, ใหญ่,  , ตั้ง, วง, กิน, เหล้า,  ...   \n",
       "1947  [ที่, เกิด, เหตุ, พบ, ศพ,  , นาย, เสถียร,  , ธ...   \n",
       "1948  [เมื่อ, เว, ลา,  , 01.30,  , น.,  , วัน, ที่, ...   \n",
       "1949  [จาก, นั้น, ทั้ง, สอง, กลุ่ม, จึง, มี, ปาก, เส...   \n",
       "\n",
       "                                                   tags  \\\n",
       "0     [O, O, O, O, B-DATE, I-DATE, I-DATE, I-DATE, O...   \n",
       "1     [O, O, O, O, B-DATE, I-DATE, I-DATE, B-PERSON,...   \n",
       "2     [O, O, O, O, O, O, O, O, B-PERSON, I-PERSON, I...   \n",
       "3     [O, O, O, O, O, O, O, O, O, O, O, B-DATE, I-DA...   \n",
       "4     [O, O, O, O, B-DATE, I-DATE, I-DATE, I-DATE, I...   \n",
       "...                                                 ...   \n",
       "1945  [O, O, O, O, B-PERSON, I-PERSON, I-PERSON, I-P...   \n",
       "1946  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "1947  [O, O, O, O, O, O, B-PERSON, I-PERSON, I-PERSO...   \n",
       "1948  [O, O, O, O, B-TIME, I-TIME, I-TIME, O, O, O, ...   \n",
       "1949  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "\n",
       "                                          contain_digit  \\\n",
       "0     [False, False, False, False, True, False, Fals...   \n",
       "1     [False, False, False, False, True, False, Fals...   \n",
       "2     [False, False, False, False, True, False, Fals...   \n",
       "3     [False, False, False, False, False, False, Fal...   \n",
       "4     [False, False, False, False, True, False, Fals...   \n",
       "...                                                 ...   \n",
       "1945  [False, False, False, False, False, False, Fal...   \n",
       "1946  [True, False, False, False, False, False, Fals...   \n",
       "1947  [False, False, False, False, False, False, Fal...   \n",
       "1948  [False, False, False, False, True, False, Fals...   \n",
       "1949  [False, False, False, False, False, False, Fal...   \n",
       "\n",
       "                                           contain_punc  \\\n",
       "0     [False, False, False, True, False, False, True...   \n",
       "1     [False, False, False, False, False, False, Tru...   \n",
       "2     [False, False, False, False, False, False, Tru...   \n",
       "3     [False, False, False, False, False, False, Fal...   \n",
       "4     [False, False, False, False, False, False, Fal...   \n",
       "...                                                 ...   \n",
       "1945  [False, False, False, False, False, False, Fal...   \n",
       "1946  [False, False, False, False, False, False, Fal...   \n",
       "1947  [False, False, False, False, False, False, Fal...   \n",
       "1948  [False, False, False, False, True, False, True...   \n",
       "1949  [False, False, False, False, False, False, Fal...   \n",
       "\n",
       "                                          contain_vowel  \\\n",
       "0     [True, True, False, False, False, False, False...   \n",
       "1     [True, True, True, False, False, False, False,...   \n",
       "2     [True, True, True, False, False, False, False,...   \n",
       "3     [False, True, True, True, True, True, False, T...   \n",
       "4     [True, True, True, False, False, False, True, ...   \n",
       "...                                                 ...   \n",
       "1945  [True, False, True, False, True, False, True, ...   \n",
       "1946  [False, False, True, True, False, True, False,...   \n",
       "1947  [True, True, True, False, False, False, True, ...   \n",
       "1948  [True, True, True, False, False, False, False,...   \n",
       "1949  [True, True, True, False, True, True, True, Tr...   \n",
       "\n",
       "                                                    pos  \n",
       "0     [NCMN, DDAC, PUNC, PUNC, DCNM, PUNC, CMTR, NCN...  \n",
       "1     [JSBR, NCMN, PREL, PUNC, DCNM, PUNC, CMTR, NCM...  \n",
       "2     [JSBR, NCMN, PREL, PUNC, DCNM, PUNC, CMTR, PUN...  \n",
       "3     [PPRS, VACT, NCMN, CNIT, NCMN, JSBR, PUNC, NCM...  \n",
       "4     [JSBR, NCMN, PREL, PUNC, DCNM, PUNC, ADVN, ADV...  \n",
       "...                                                 ...  \n",
       "1945  [RPRE, NCMN, VACT, PUNC, NTTL, NPRP, NPRP, PUN...  \n",
       "1946  [NLBL, PUNC, NCMN, VATT, PUNC, VACT, NCMN, VAC...  \n",
       "1947  [PREL, VSTA, NCMN, VSTA, NPRP, PUNC, NTTL, NPR...  \n",
       "1948  [JSBR, NCMN, NCMN, PUNC, DCNM, PUNC, CMTR, PUN...  \n",
       "1949  [RPRE, DDAC, DDBQ, DCNM, CLTV, XVBM, VSTA, NCM...  \n",
       "\n",
       "[1950 rows x 7 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_q = read_all_file(PATH = 'data/csd_rel_data_annotated/')\n",
    "# df_p = read_all_file(PATH = 'data/csd_rel_data2_annotated/')\n",
    "\n",
    "# for i in df_q.columns:\n",
    "#     df_q[i] = df_q[i].apply(lambda x: x[0])\n",
    "#     df_p[i] = df_p[i].apply(lambda x: x[0])\n",
    "\n",
    "# df_p['pos'] = df_p['words'].apply(lambda x : [i[1] for i in pythainlp.tag.pos_tag(x)])\n",
    "# df_q['pos'] = df_q['words'].apply(lambda x : [i[1] for i in pythainlp.tag.pos_tag(x)])\n",
    "\n",
    "    \n",
    "df_Coraline = pd.read_csv('[NER]Coraline_annotation_prepared_df.csv').drop(columns = 'Unnamed: 0')\n",
    "for i in ['words', 'contain_digit', 'contain_punc', 'contain_vowel', 'tags', 'pos']:\n",
    "    df_Coraline[i] = df_Coraline[i].str.strip('[]').str.split(', ').apply(lambda x: [i[1:-1] for i in x])\n",
    "\n",
    "\n",
    "    \n",
    "# df = pd.concat([df_Coraline, df], ignore_index = True)\n",
    "\n",
    "# df.head()\n",
    "# pd.concat([df_q, df_p, df_Coraline], ignore_index = True)\n",
    "df = pd.concat([df_q, df_p, df_Coraline], ignore_index = True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3afb4bcb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T08:46:29.151231Z",
     "start_time": "2022-01-26T08:45:50.513622Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-53a26150e48f>:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train['words_idx'] = train['words'].apply(lambda x: [word2idx[i] for i in x])\n",
      "<ipython-input-3-53a26150e48f>:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train['pos_idx'] = train['pos'].apply(lambda x: [pos2idx[i] for i in x])\n",
      "<ipython-input-3-53a26150e48f>:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train['tags_idx'] = train['tags'].apply(lambda x: [tag2idx[i] for i in x])\n",
      "<ipython-input-3-53a26150e48f>:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train['contain_digit_idx'] = train['contain_digit'].apply(lambda x: [digit2idx[i] for i in x])\n",
      "<ipython-input-3-53a26150e48f>:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train['contain_punc_idx'] = train['contain_punc'].apply(lambda x: [punc2idx[i] for i in x])\n",
      "<ipython-input-3-53a26150e48f>:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train['contain_vowel_idx'] = train['contain_vowel'].apply(lambda x: [vowel2idx[i] for i in x])\n",
      "<ipython-input-3-53a26150e48f>:66: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test['words_idx'] = test_sent\n",
      "<ipython-input-3-53a26150e48f>:67: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test['pos_idx'] = test_pos\n",
      "<ipython-input-3-53a26150e48f>:68: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test['tags_idx'] = test_tag\n",
      "<ipython-input-3-53a26150e48f>:69: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test['contain_digit_idx'] = test['contain_digit'].apply(lambda x: [digit2idx[i] for i in x])\n",
      "<ipython-input-3-53a26150e48f>:70: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test['contain_punc_idx'] = test['contain_punc'].apply(lambda x: [punc2idx[i] for i in x])\n",
      "<ipython-input-3-53a26150e48f>:71: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test['contain_vowel_idx'] = test['contain_vowel'].apply(lambda x: [vowel2idx[i] for i in x])\n",
      "<ipython-input-16-7d475033a5e4>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train['padded_words_idx'] = list(pad_sequences(train['words_idx'], maxlen = max_len, padding = 'post', value = mapping['tok2idx']['<PAD>']))\n",
      "<ipython-input-16-7d475033a5e4>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train['padded_pos_idx'] = list(pad_sequences(train['pos_idx'], maxlen = max_len, padding = 'post', value = mapping['pos2idx']['<PAD>']))\n",
      "<ipython-input-16-7d475033a5e4>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train['padded_tags_idx'] = list(pad_sequences(train['tags_idx'], maxlen = max_len, padding = 'post', value = mapping['tag2idx']['<PAD>']))\n",
      "<ipython-input-16-7d475033a5e4>:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train['padded_contain_digit_idx'] = list(pad_sequences(train['contain_digit_idx'], maxlen = max_len, padding = 'post', value = 2))\n",
      "<ipython-input-16-7d475033a5e4>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train['padded_contain_punc_idx'] = list(pad_sequences(train['contain_punc_idx'], maxlen = max_len, padding = 'post', value = 2))\n",
      "<ipython-input-16-7d475033a5e4>:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train['padded_contain_vowel_idx'] = list(pad_sequences(train['contain_vowel_idx'], maxlen = max_len, padding = 'post', value = 2))\n",
      "<ipython-input-16-7d475033a5e4>:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test['padded_words_idx'] = list(pad_sequences(test['words_idx'], maxlen = max_len, padding = 'post', value = mapping['tok2idx']['<PAD>']))\n",
      "<ipython-input-16-7d475033a5e4>:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test['padded_pos_idx'] = list(pad_sequences(test['pos_idx'], maxlen = max_len, padding = 'post', value = mapping['pos2idx']['<PAD>']))\n",
      "<ipython-input-16-7d475033a5e4>:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test['padded_tags_idx'] = list(pad_sequences(test['tags_idx'], maxlen = max_len, padding = 'post', value = mapping['tag2idx']['<PAD>']))\n",
      "<ipython-input-16-7d475033a5e4>:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test['padded_contain_digit_idx'] = list(pad_sequences(test['contain_digit_idx'], maxlen = max_len, padding = 'post', value = 2))\n",
      "<ipython-input-16-7d475033a5e4>:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test['padded_contain_punc_idx'] = list(pad_sequences(test['contain_punc_idx'], maxlen = max_len, padding = 'post', value = 2))\n",
      "<ipython-input-16-7d475033a5e4>:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test['padded_contain_vowel_idx'] = list(pad_sequences(test['contain_vowel_idx'], maxlen = max_len, padding = 'post', value = 2))\n"
     ]
    }
   ],
   "source": [
    "train, test, mapping, max_len = return_train_test(df)\n",
    "\n",
    "train['padded_words_idx'] = list(pad_sequences(train['words_idx'], maxlen = max_len, padding = 'post', value = mapping['tok2idx']['<PAD>']))\n",
    "train['padded_pos_idx'] = list(pad_sequences(train['pos_idx'], maxlen = max_len, padding = 'post', value = mapping['pos2idx']['<PAD>']))\n",
    "train['padded_tags_idx'] = list(pad_sequences(train['tags_idx'], maxlen = max_len, padding = 'post', value = mapping['tag2idx']['<PAD>']))\n",
    "train['padded_contain_digit_idx'] = list(pad_sequences(train['contain_digit_idx'], maxlen = max_len, padding = 'post', value = 2))\n",
    "train['padded_contain_punc_idx'] = list(pad_sequences(train['contain_punc_idx'], maxlen = max_len, padding = 'post', value = 2))\n",
    "train['padded_contain_vowel_idx'] = list(pad_sequences(train['contain_vowel_idx'], maxlen = max_len, padding = 'post', value = 2))\n",
    "\n",
    "test['padded_words_idx'] = list(pad_sequences(test['words_idx'], maxlen = max_len, padding = 'post', value = mapping['tok2idx']['<PAD>']))\n",
    "test['padded_pos_idx'] = list(pad_sequences(test['pos_idx'], maxlen = max_len, padding = 'post', value = mapping['pos2idx']['<PAD>']))\n",
    "test['padded_tags_idx'] = list(pad_sequences(test['tags_idx'], maxlen = max_len, padding = 'post', value = mapping['tag2idx']['<PAD>']))\n",
    "test['padded_contain_digit_idx'] = list(pad_sequences(test['contain_digit_idx'], maxlen = max_len, padding = 'post', value = 2))\n",
    "test['padded_contain_punc_idx'] = list(pad_sequences(test['contain_punc_idx'], maxlen = max_len, padding = 'post', value = 2))\n",
    "test['padded_contain_vowel_idx'] = list(pad_sequences(test['contain_vowel_idx'], maxlen = max_len, padding = 'post', value = 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "db6879ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T08:46:30.271629Z",
     "start_time": "2022-01-26T08:46:30.257273Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6032"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.iloc[0]['padded_words_idx'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a71020e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T08:47:00.641286Z",
     "start_time": "2022-01-26T08:47:00.387036Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_6 (InputLayer)           [(None, 1668)]       0           []                               \n",
      "                                                                                                  \n",
      " input_7 (InputLayer)           [(None, 1668)]       0           []                               \n",
      "                                                                                                  \n",
      " input_8 (InputLayer)           [(None, 1668)]       0           []                               \n",
      "                                                                                                  \n",
      " input_9 (InputLayer)           [(None, 1668)]       0           []                               \n",
      "                                                                                                  \n",
      " input_10 (InputLayer)          [(None, 1668)]       0           []                               \n",
      "                                                                                                  \n",
      " embedding_5 (Embedding)        (None, 1668, 8)      48264       ['input_6[0][0]']                \n",
      "                                                                                                  \n",
      " embedding_6 (Embedding)        (None, 1668, 8)      48264       ['input_7[0][0]']                \n",
      "                                                                                                  \n",
      " embedding_7 (Embedding)        (None, 1668, 8)      48264       ['input_8[0][0]']                \n",
      "                                                                                                  \n",
      " embedding_8 (Embedding)        (None, 1668, 8)      48264       ['input_9[0][0]']                \n",
      "                                                                                                  \n",
      " embedding_9 (Embedding)        (None, 1668, 8)      48264       ['input_10[0][0]']               \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 1668, 40)     0           ['embedding_5[0][0]',            \n",
      "                                                                  'embedding_6[0][0]',            \n",
      "                                                                  'embedding_7[0][0]',            \n",
      "                                                                  'embedding_8[0][0]',            \n",
      "                                                                  'embedding_9[0][0]']            \n",
      "                                                                                                  \n",
      " bidirectional_1 (Bidirectional  (None, 1668, 16)    3136        ['concatenate_1[0][0]']          \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " time_distributed_1 (TimeDistri  (None, 1668, 22)    374         ['bidirectional_1[0][0]']        \n",
      " buted)                                                                                           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 244,830\n",
      "Trainable params: 244,830\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# !pip install sklearn_crfsuite\n",
    "from tensorflow.keras import backend as K\n",
    "from focal_loss import sparse_categorical_focal_loss\n",
    "from transformers import AutoModel\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from keras_contrib.layers import CRF\n",
    "\n",
    "def focal_loss(y_true, y_pred):\n",
    "    \n",
    "    # Loss for imbalanced dataset --> weight more for minor class, weight less for major class\n",
    "    \n",
    "    class_weight = [10,10,10,15,15,\n",
    "                    10,10,10,10,15,\n",
    "                    10,10,10,15,15,\n",
    "                    10,10,10,10,10,\n",
    "                    1, 0.01 \n",
    "                    ]\n",
    "    loss = sparse_categorical_focal_loss(y_true, y_pred, gamma=2, class_weight = class_weight)\n",
    "                                                                       \n",
    "    return loss\n",
    "\n",
    "def train_model(X, y, model):\n",
    "    loss = list()\n",
    "    \n",
    "    # Add class weight\n",
    "    \n",
    "    \n",
    "#     for i in range(150):\n",
    "        # fit model for one epoch on this sequence\n",
    "    hist = model.fit(X, y, batch_size=64,  verbose=1, epochs=60, validation_split=0.2 )\n",
    "    loss.append(hist.history['loss'][0])\n",
    "    return model, loss\n",
    "\n",
    "label = mapping['tag2idx']\n",
    "\n",
    "input_dim_long = 6032 + 1\n",
    "\n",
    "input_len_long = len(train['padded_words_idx'].iloc[0])\n",
    "\n",
    "n_tags = len(label)\n",
    "output_dim = 8\n",
    "\n",
    "model_words = Input(shape = (input_len_long,))\n",
    "emb_words = Embedding(input_dim=input_dim_long, output_dim=output_dim)(model_words)\n",
    "# output_words = Reshape(target_shape=(output_dim, input_len_long))(emb_words)\n",
    "\n",
    "model_pos = Input(shape = (input_len_long,))\n",
    "emb_pos = Embedding(input_dim=input_dim_long, output_dim=output_dim)(model_pos)\n",
    "# output_pos = Reshape(target_shape=(output_dim, input_len_long))(emb_pos)\n",
    "model_digit = Input(shape = (input_len_long,))\n",
    "emb_digit = Embedding(input_dim=input_dim_long, output_dim=output_dim)(model_digit)\n",
    "\n",
    "model_punc = Input(shape = (input_len_long,))\n",
    "emb_punc = Embedding(input_dim=input_dim_long, output_dim=output_dim)(model_punc)\n",
    "\n",
    "model_vowel = Input(shape = (input_len_long,))\n",
    "emb_vowel = Embedding(input_dim=input_dim_long, output_dim=output_dim)(model_vowel)\n",
    "\n",
    "\n",
    "input_model = [model_words, model_pos, model_digit, model_punc, model_vowel]\n",
    "\n",
    "output_embeddings = [emb_words, emb_pos, emb_digit, emb_punc, emb_vowel]\n",
    "\n",
    "output_model = Concatenate()(output_embeddings)\n",
    "output_model = Bidirectional(LSTM(units=output_dim, return_sequences=True, dropout=0.5, recurrent_dropout=0.5))(output_model)\n",
    "output_model = TimeDistributed(Dense(n_tags, activation=\"softmax\"))(output_model)\n",
    "\n",
    "model = Model(inputs = input_model, outputs = output_model)\n",
    "    \n",
    "model.compile(loss= [focal_loss], \n",
    "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.01, epsilon=1e-08), \n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ec5e9bbf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T12:05:56.619582Z",
     "start_time": "2022-01-26T08:47:01.544585Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "20/20 [==============================] - 154s 8s/step - loss: 1.2636 - accuracy: 0.1752 - val_loss: 1.0765 - val_accuracy: 0.0420\n",
      "Epoch 2/60\n",
      "20/20 [==============================] - 168s 8s/step - loss: 0.9286 - accuracy: 0.4091 - val_loss: 0.7643 - val_accuracy: 0.9385\n",
      "Epoch 3/60\n",
      "20/20 [==============================] - 168s 8s/step - loss: 0.6528 - accuracy: 0.9474 - val_loss: 0.4975 - val_accuracy: 0.9527\n",
      "Epoch 4/60\n",
      "20/20 [==============================] - 176s 9s/step - loss: 0.4423 - accuracy: 0.9560 - val_loss: 0.3272 - val_accuracy: 0.9588\n",
      "Epoch 5/60\n",
      "20/20 [==============================] - 185s 9s/step - loss: 0.3149 - accuracy: 0.9620 - val_loss: 0.2503 - val_accuracy: 0.9591\n",
      "Epoch 6/60\n",
      "20/20 [==============================] - 183s 9s/step - loss: 0.2511 - accuracy: 0.9647 - val_loss: 0.2085 - val_accuracy: 0.9658\n",
      "Epoch 7/60\n",
      "20/20 [==============================] - 185s 9s/step - loss: 0.2135 - accuracy: 0.9673 - val_loss: 0.1871 - val_accuracy: 0.9646\n",
      "Epoch 8/60\n",
      "20/20 [==============================] - 186s 9s/step - loss: 0.1893 - accuracy: 0.9692 - val_loss: 0.1744 - val_accuracy: 0.9674\n",
      "Epoch 9/60\n",
      "20/20 [==============================] - 187s 9s/step - loss: 0.1774 - accuracy: 0.9691 - val_loss: 0.1701 - val_accuracy: 0.9700\n",
      "Epoch 10/60\n",
      "20/20 [==============================] - 191s 10s/step - loss: 0.1645 - accuracy: 0.9711 - val_loss: 0.1620 - val_accuracy: 0.9695\n",
      "Epoch 11/60\n",
      "20/20 [==============================] - 187s 9s/step - loss: 0.1562 - accuracy: 0.9710 - val_loss: 0.1574 - val_accuracy: 0.9709\n",
      "Epoch 12/60\n",
      "20/20 [==============================] - 185s 9s/step - loss: 0.1498 - accuracy: 0.9717 - val_loss: 0.1566 - val_accuracy: 0.9662\n",
      "Epoch 13/60\n",
      "20/20 [==============================] - 187s 9s/step - loss: 0.1464 - accuracy: 0.9723 - val_loss: 0.1528 - val_accuracy: 0.9684\n",
      "Epoch 14/60\n",
      "20/20 [==============================] - 190s 10s/step - loss: 0.1431 - accuracy: 0.9709 - val_loss: 0.1498 - val_accuracy: 0.9696\n",
      "Epoch 15/60\n",
      "20/20 [==============================] - 192s 10s/step - loss: 0.1372 - accuracy: 0.9722 - val_loss: 0.1482 - val_accuracy: 0.9716\n",
      "Epoch 16/60\n",
      "20/20 [==============================] - 207s 10s/step - loss: 0.1349 - accuracy: 0.9731 - val_loss: 0.1468 - val_accuracy: 0.9673\n",
      "Epoch 17/60\n",
      "20/20 [==============================] - 204s 10s/step - loss: 0.1309 - accuracy: 0.9721 - val_loss: 0.1455 - val_accuracy: 0.9712\n",
      "Epoch 18/60\n",
      "20/20 [==============================] - 205s 10s/step - loss: 0.1286 - accuracy: 0.9737 - val_loss: 0.1460 - val_accuracy: 0.9700\n",
      "Epoch 19/60\n",
      "20/20 [==============================] - 206s 10s/step - loss: 0.1261 - accuracy: 0.9737 - val_loss: 0.1449 - val_accuracy: 0.9686\n",
      "Epoch 20/60\n",
      "20/20 [==============================] - 202s 10s/step - loss: 0.1242 - accuracy: 0.9736 - val_loss: 0.1409 - val_accuracy: 0.9710\n",
      "Epoch 21/60\n",
      "20/20 [==============================] - 199s 10s/step - loss: 0.1209 - accuracy: 0.9735 - val_loss: 0.1424 - val_accuracy: 0.9718\n",
      "Epoch 22/60\n",
      "20/20 [==============================] - 201s 10s/step - loss: 0.1209 - accuracy: 0.9745 - val_loss: 0.1404 - val_accuracy: 0.9719\n",
      "Epoch 23/60\n",
      "20/20 [==============================] - 200s 10s/step - loss: 0.1184 - accuracy: 0.9741 - val_loss: 0.1380 - val_accuracy: 0.9702\n",
      "Epoch 24/60\n",
      "20/20 [==============================] - 200s 10s/step - loss: 0.1181 - accuracy: 0.9741 - val_loss: 0.1394 - val_accuracy: 0.9713\n",
      "Epoch 25/60\n",
      "20/20 [==============================] - 201s 10s/step - loss: 0.1150 - accuracy: 0.9745 - val_loss: 0.1382 - val_accuracy: 0.9709\n",
      "Epoch 26/60\n",
      "20/20 [==============================] - 200s 10s/step - loss: 0.1154 - accuracy: 0.9747 - val_loss: 0.1374 - val_accuracy: 0.9729\n",
      "Epoch 27/60\n",
      "20/20 [==============================] - 201s 10s/step - loss: 0.1139 - accuracy: 0.9748 - val_loss: 0.1391 - val_accuracy: 0.9717\n",
      "Epoch 28/60\n",
      "20/20 [==============================] - 216s 11s/step - loss: 0.1135 - accuracy: 0.9747 - val_loss: 0.1360 - val_accuracy: 0.9704\n",
      "Epoch 29/60\n",
      "20/20 [==============================] - 202s 10s/step - loss: 0.1131 - accuracy: 0.9750 - val_loss: 0.1368 - val_accuracy: 0.9718\n",
      "Epoch 30/60\n",
      "20/20 [==============================] - 202s 10s/step - loss: 0.1118 - accuracy: 0.9750 - val_loss: 0.1369 - val_accuracy: 0.9731\n",
      "Epoch 31/60\n",
      "20/20 [==============================] - 203s 10s/step - loss: 0.1119 - accuracy: 0.9754 - val_loss: 0.1354 - val_accuracy: 0.9697\n",
      "Epoch 32/60\n",
      "20/20 [==============================] - 204s 10s/step - loss: 0.1113 - accuracy: 0.9752 - val_loss: 0.1348 - val_accuracy: 0.9728\n",
      "Epoch 33/60\n",
      "20/20 [==============================] - 204s 10s/step - loss: 0.1078 - accuracy: 0.9759 - val_loss: 0.1351 - val_accuracy: 0.9705\n",
      "Epoch 34/60\n",
      "20/20 [==============================] - 204s 10s/step - loss: 0.1076 - accuracy: 0.9756 - val_loss: 0.1356 - val_accuracy: 0.9703\n",
      "Epoch 35/60\n",
      "20/20 [==============================] - 208s 10s/step - loss: 0.1071 - accuracy: 0.9753 - val_loss: 0.1337 - val_accuracy: 0.9726\n",
      "Epoch 36/60\n",
      "20/20 [==============================] - 207s 10s/step - loss: 0.1041 - accuracy: 0.9759 - val_loss: 0.1333 - val_accuracy: 0.9722\n",
      "Epoch 37/60\n",
      "20/20 [==============================] - 202s 10s/step - loss: 0.1052 - accuracy: 0.9758 - val_loss: 0.1323 - val_accuracy: 0.9703\n",
      "Epoch 38/60\n",
      "20/20 [==============================] - 203s 10s/step - loss: 0.1050 - accuracy: 0.9758 - val_loss: 0.1333 - val_accuracy: 0.9714\n",
      "Epoch 39/60\n",
      "20/20 [==============================] - 202s 10s/step - loss: 0.1038 - accuracy: 0.9758 - val_loss: 0.1302 - val_accuracy: 0.9729\n",
      "Epoch 40/60\n",
      "20/20 [==============================] - 208s 10s/step - loss: 0.1037 - accuracy: 0.9765 - val_loss: 0.1313 - val_accuracy: 0.9739\n",
      "Epoch 41/60\n",
      "20/20 [==============================] - 206s 10s/step - loss: 0.1023 - accuracy: 0.9763 - val_loss: 0.1330 - val_accuracy: 0.9704\n",
      "Epoch 42/60\n",
      "20/20 [==============================] - 203s 10s/step - loss: 0.1023 - accuracy: 0.9764 - val_loss: 0.1323 - val_accuracy: 0.9732\n",
      "Epoch 43/60\n",
      "20/20 [==============================] - 203s 10s/step - loss: 0.1014 - accuracy: 0.9767 - val_loss: 0.1321 - val_accuracy: 0.9722\n",
      "Epoch 44/60\n",
      "20/20 [==============================] - 223s 11s/step - loss: 0.1014 - accuracy: 0.9768 - val_loss: 0.1318 - val_accuracy: 0.9714\n",
      "Epoch 45/60\n",
      "20/20 [==============================] - 206s 10s/step - loss: 0.1000 - accuracy: 0.9764 - val_loss: 0.1309 - val_accuracy: 0.9733\n",
      "Epoch 46/60\n",
      "20/20 [==============================] - 203s 10s/step - loss: 0.0994 - accuracy: 0.9770 - val_loss: 0.1300 - val_accuracy: 0.9724\n",
      "Epoch 47/60\n",
      "20/20 [==============================] - 204s 10s/step - loss: 0.0980 - accuracy: 0.9769 - val_loss: 0.1299 - val_accuracy: 0.9729\n",
      "Epoch 48/60\n",
      "20/20 [==============================] - 202s 10s/step - loss: 0.0998 - accuracy: 0.9772 - val_loss: 0.1335 - val_accuracy: 0.9718\n",
      "Epoch 49/60\n",
      "20/20 [==============================] - 205s 10s/step - loss: 0.0991 - accuracy: 0.9766 - val_loss: 0.1299 - val_accuracy: 0.9739\n",
      "Epoch 50/60\n",
      "20/20 [==============================] - 208s 10s/step - loss: 0.0988 - accuracy: 0.9773 - val_loss: 0.1303 - val_accuracy: 0.9729\n",
      "Epoch 51/60\n",
      "20/20 [==============================] - 205s 10s/step - loss: 0.0964 - accuracy: 0.9772 - val_loss: 0.1298 - val_accuracy: 0.9736\n",
      "Epoch 52/60\n",
      "20/20 [==============================] - 205s 10s/step - loss: 0.0975 - accuracy: 0.9769 - val_loss: 0.1300 - val_accuracy: 0.9718\n",
      "Epoch 53/60\n",
      "20/20 [==============================] - 204s 10s/step - loss: 0.0968 - accuracy: 0.9771 - val_loss: 0.1301 - val_accuracy: 0.9726\n",
      "Epoch 54/60\n",
      "20/20 [==============================] - 205s 10s/step - loss: 0.0970 - accuracy: 0.9773 - val_loss: 0.1291 - val_accuracy: 0.9756\n",
      "Epoch 55/60\n",
      "20/20 [==============================] - 204s 10s/step - loss: 0.0958 - accuracy: 0.9778 - val_loss: 0.1309 - val_accuracy: 0.9717\n",
      "Epoch 56/60\n",
      "20/20 [==============================] - 207s 10s/step - loss: 0.0952 - accuracy: 0.9772 - val_loss: 0.1292 - val_accuracy: 0.9745\n",
      "Epoch 57/60\n",
      "20/20 [==============================] - 204s 10s/step - loss: 0.0949 - accuracy: 0.9775 - val_loss: 0.1296 - val_accuracy: 0.9727\n",
      "Epoch 58/60\n",
      "20/20 [==============================] - 205s 10s/step - loss: 0.0941 - accuracy: 0.9777 - val_loss: 0.1291 - val_accuracy: 0.9718\n",
      "Epoch 59/60\n",
      "20/20 [==============================] - 209s 10s/step - loss: 0.0938 - accuracy: 0.9775 - val_loss: 0.1270 - val_accuracy: 0.9735\n",
      "Epoch 60/60\n",
      "20/20 [==============================] - 206s 10s/step - loss: 0.0918 - accuracy: 0.9779 - val_loss: 0.1292 - val_accuracy: 0.9740\n"
     ]
    }
   ],
   "source": [
    "input_dim = 6032 + 1\n",
    "output_dim = 8\n",
    "input_length = max_len\n",
    "n_tags = len(label)\n",
    "\n",
    "X_tr_words = []\n",
    "for i in train['padded_words_idx']:\n",
    "    X_tr_words.append(i)\n",
    "X_tr_words = np.array(X_tr_words)\n",
    "\n",
    "X_tr_pos = []\n",
    "for i in train['padded_pos_idx']:\n",
    "    X_tr_pos.append(i)\n",
    "X_tr_pos = np.array(X_tr_pos)\n",
    "\n",
    "X_tr_digit = []\n",
    "for i in train['padded_contain_digit_idx']:\n",
    "    X_tr_digit.append(i)\n",
    "X_tr_digit = np.array(X_tr_digit)\n",
    "\n",
    "X_tr_punc = []\n",
    "for i in train['padded_contain_punc_idx']:\n",
    "    X_tr_punc.append(i)\n",
    "X_tr_punc = np.array(X_tr_punc)\n",
    "\n",
    "X_tr_vowel = []\n",
    "for i in train['padded_contain_vowel_idx']:\n",
    "    X_tr_vowel.append(i)\n",
    "X_tr_vowel = np.array(X_tr_vowel)\n",
    "\n",
    "y_train = [i for i in train['padded_tags_idx']]\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "model = train_model([X_tr_words, X_tr_pos, X_tr_digit, X_tr_punc, X_tr_vowel], y_train, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c3a556a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T12:51:26.447632Z",
     "start_time": "2022-01-26T12:51:26.428209Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5176, 5273, 3807, ..., 6032, 6032, 6032],\n",
       "       [5176, 5273, 3807, ..., 6032, 6032, 6032],\n",
       "       [1805, 3352, 3877, ..., 6032, 6032, 6032],\n",
       "       ...,\n",
       "       [3924, 2688,    0, ..., 6032, 6032, 6032],\n",
       "       [3606, 2868, 4219, ..., 6032, 6032, 6032],\n",
       "       [3924, 2498,    0, ..., 6032, 6032, 6032]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tr_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "009b6a6c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T12:06:14.337307Z",
     "start_time": "2022-01-26T12:06:09.216240Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "       B-COLOR       0.62      0.86      0.72       139\n",
      "        B-DATE       0.74      0.92      0.82       425\n",
      "    B-LOCATION       0.66      0.87      0.75      1979\n",
      "          B-LP       0.52      0.65      0.58        85\n",
      "      B-OBJECT       0.32      0.49      0.39       222\n",
      "B-ORGANIZATION       0.52      0.85      0.64       806\n",
      "      B-PERSON       0.79      0.93      0.85      1647\n",
      "        B-TIME       0.77      0.97      0.86       711\n",
      "     B-VEHICLE       0.53      0.90      0.67       432\n",
      "      B-WEAPON       0.33      0.90      0.48       376\n",
      "       I-COLOR       0.48      0.94      0.64       186\n",
      "        I-DATE       0.73      0.96      0.83      1394\n",
      "    I-LOCATION       0.67      0.89      0.76      5968\n",
      "          I-LP       0.51      0.94      0.66       525\n",
      "      I-OBJECT       0.25      0.54      0.34       694\n",
      "I-ORGANIZATION       0.49      0.82      0.62      3339\n",
      "      I-PERSON       0.67      0.95      0.79      6968\n",
      "        I-TIME       0.78      0.96      0.86      1449\n",
      "     I-VEHICLE       0.69      0.93      0.80      1482\n",
      "      I-WEAPON       0.41      0.73      0.53       545\n",
      "             O       0.98      0.85      0.91     87616\n",
      "         <PAD>       1.00      1.00      1.00    533532\n",
      "\n",
      "      accuracy                           0.97    650520\n",
      "     macro avg       0.61      0.86      0.70    650520\n",
      "  weighted avg       0.98      0.97      0.98    650520\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_te_words = []\n",
    "for i in test['padded_words_idx']:\n",
    "    X_te_words.append(i)\n",
    "X_te_words = np.array(X_te_words)\n",
    "\n",
    "X_te_pos = []\n",
    "for i in test['padded_pos_idx']:\n",
    "    X_te_pos.append(i)\n",
    "X_te_pos = np.array(X_te_pos)\n",
    "\n",
    "X_te_digit = []\n",
    "for i in test['padded_contain_digit_idx']:\n",
    "    X_te_digit.append(i)\n",
    "X_te_digit = np.array(X_te_digit)\n",
    "\n",
    "X_te_punc = []\n",
    "for i in test['padded_contain_punc_idx']:\n",
    "    X_te_punc.append(i)\n",
    "X_te_punc = np.array(X_te_punc)\n",
    "\n",
    "X_te_vowel = []\n",
    "for i in test['padded_contain_vowel_idx']:\n",
    "    X_te_vowel.append(i)\n",
    "X_te_vowel = np.array(X_te_vowel)\n",
    "\n",
    "y_pred = model[0].predict([X_te_words, X_te_pos, X_te_digit, X_te_punc, X_te_vowel])\n",
    "y_pred = np.argmax(y_pred, axis = 2)\n",
    "y_test = []\n",
    "for i in test['padded_tags_idx']:\n",
    "    y_test.append(i)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "print(classification_report(y_test.reshape(y_pred.shape[0]*y_pred.shape[1]), \n",
    "                            y_pred.reshape(y_pred.shape[0]*y_pred.shape[1]),\n",
    "                           target_names = label.keys())\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8c71c1e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T12:08:48.133716Z",
     "start_time": "2022-01-26T12:08:48.065090Z"
    }
   },
   "outputs": [],
   "source": [
    "model[0].save('NER_model_v2_26_1_2022.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d6208797",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T12:25:04.372597Z",
     "start_time": "2022-01-26T12:25:04.334149Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tok2idx': {' ': 0,\n",
       "  '  ': 1,\n",
       "  '   ': 2,\n",
       "  '\"': 3,\n",
       "  '\"#': 4,\n",
       "  '\"ชน': 5,\n",
       "  '\"ตก': 6,\n",
       "  '\"พบศพ\"': 7,\n",
       "  '#': 8,\n",
       "  '%': 9,\n",
       "  '(': 10,\n",
       "  '(ขอ': 11,\n",
       "  '(คน': 12,\n",
       "  '(จ)': 13,\n",
       "  '(จต': 14,\n",
       "  '(ช': 15,\n",
       "  '(ตก': 16,\n",
       "  '(บ': 17,\n",
       "  '(บช': 18,\n",
       "  '(ผ': 19,\n",
       "  '(ผบ': 20,\n",
       "  '(พฐ.)': 21,\n",
       "  '(พฐ.)\\u200b': 22,\n",
       "  '(พบ': 23,\n",
       "  '(ม': 24,\n",
       "  '(ศ': 25,\n",
       "  '(ศป': 26,\n",
       "  '(ศปอ': 27,\n",
       "  '(ศพฐ.)': 28,\n",
       "  '(ส': 29,\n",
       "  '(ส)': 30,\n",
       "  '(สบ': 31,\n",
       "  '(สพฐ.ตร)': 32,\n",
       "  '(์': 33,\n",
       "  ')': 34,\n",
       "  '),': 35,\n",
       "  ')\\u200b': 36,\n",
       "  '+': 37,\n",
       "  ',': 38,\n",
       "  '-': 39,\n",
       "  '.': 40,\n",
       "  '.(': 41,\n",
       "  '.(นบ)': 42,\n",
       "  '.)': 43,\n",
       "  '.,': 44,\n",
       "  '.กก': 45,\n",
       "  '.ค': 46,\n",
       "  '.ช': 47,\n",
       "  '.ตก': 48,\n",
       "  '.ตน': 49,\n",
       "  '.ตอ': 50,\n",
       "  '.ท': 51,\n",
       "  '.บ': 52,\n",
       "  '.ป': 53,\n",
       "  '.ป,': 54,\n",
       "  '.ปค': 55,\n",
       "  '.ปคม': 56,\n",
       "  '.ปป': 57,\n",
       "  '.ปพ': 58,\n",
       "  '.ปอ': 59,\n",
       "  '.ฝ': 60,\n",
       "  '.ย': 61,\n",
       "  '.ร': 62,\n",
       "  '.ษ.': 63,\n",
       "  '.สส': 64,\n",
       "  '.อ': 65,\n",
       "  '.อคฝ.': 66,\n",
       "  '.อม': 67,\n",
       "  '.\\u200b': 68,\n",
       "  '/': 69,\n",
       "  '0': 70,\n",
       "  '0.1': 71,\n",
       "  '0.25': 72,\n",
       "  '0.51': 73,\n",
       "  '00.00': 74,\n",
       "  '00.08': 75,\n",
       "  '00.10': 76,\n",
       "  '00.15': 77,\n",
       "  '00.20': 78,\n",
       "  '00.21': 79,\n",
       "  '00.30': 80,\n",
       "  '00.50': 81,\n",
       "  '000': 82,\n",
       "  '001': 83,\n",
       "  '01.00': 84,\n",
       "  '01.03': 85,\n",
       "  '01.20': 86,\n",
       "  '01.30': 87,\n",
       "  '01.34': 88,\n",
       "  '01.44': 89,\n",
       "  '01.45': 90,\n",
       "  '01.50': 91,\n",
       "  '0184': 92,\n",
       "  '02.00': 93,\n",
       "  '02.15': 94,\n",
       "  '02.20': 95,\n",
       "  '02.21': 96,\n",
       "  '02.30': 97,\n",
       "  '02.38': 98,\n",
       "  '02.40': 99,\n",
       "  '02.50': 100,\n",
       "  '0211': 101,\n",
       "  '03': 102,\n",
       "  '03.00': 103,\n",
       "  '03.10': 104,\n",
       "  '03.20': 105,\n",
       "  '03.30': 106,\n",
       "  '03.38': 107,\n",
       "  '03.45': 108,\n",
       "  '03.50': 109,\n",
       "  '03.55': 110,\n",
       "  '0355': 111,\n",
       "  '04': 112,\n",
       "  '04.00': 113,\n",
       "  '04.20': 114,\n",
       "  '04.30': 115,\n",
       "  '04.40': 116,\n",
       "  '05': 117,\n",
       "  '05.00': 118,\n",
       "  '05.04': 119,\n",
       "  '05.20': 120,\n",
       "  '05.30': 121,\n",
       "  '05.50': 122,\n",
       "  '06.00': 123,\n",
       "  '06.15': 124,\n",
       "  '06.30': 125,\n",
       "  '07.00': 126,\n",
       "  '07.20': 127,\n",
       "  '07.30': 128,\n",
       "  '07.45': 129,\n",
       "  '0709': 130,\n",
       "  '08': 131,\n",
       "  '08.00': 132,\n",
       "  '08.20': 133,\n",
       "  '08.30': 134,\n",
       "  '09.00': 135,\n",
       "  '09.10': 136,\n",
       "  '09.15': 137,\n",
       "  '09.20': 138,\n",
       "  '09.30': 139,\n",
       "  '09.40': 140,\n",
       "  '0936': 141,\n",
       "  '09572': 142,\n",
       "  '1': 143,\n",
       "  '1,': 144,\n",
       "  '1,000': 145,\n",
       "  '1,000,000': 146,\n",
       "  '1,010': 147,\n",
       "  '1,050,000': 148,\n",
       "  '1,070,000': 149,\n",
       "  '1,080,000': 150,\n",
       "  '1,100': 151,\n",
       "  '1,393,600': 152,\n",
       "  '1,500': 153,\n",
       "  '1,500,000': 154,\n",
       "  '1,600': 155,\n",
       "  '1,600,000': 156,\n",
       "  '1,700': 157,\n",
       "  '1,800,000': 158,\n",
       "  '1,965': 159,\n",
       "  '1,999': 160,\n",
       "  '1.': 161,\n",
       "  '1.6': 162,\n",
       "  '1.85': 163,\n",
       "  '10': 164,\n",
       "  '10,000': 165,\n",
       "  '10.00': 166,\n",
       "  '10.20': 167,\n",
       "  '10.25': 168,\n",
       "  '10.30': 169,\n",
       "  '10.45': 170,\n",
       "  '10.50': 171,\n",
       "  '10.57': 172,\n",
       "  '100': 173,\n",
       "  '100,': 174,\n",
       "  '100,000': 175,\n",
       "  '1000': 176,\n",
       "  '101': 177,\n",
       "  '101.33': 178,\n",
       "  '102': 179,\n",
       "  '104': 180,\n",
       "  '105': 181,\n",
       "  '106': 182,\n",
       "  '107': 183,\n",
       "  '1072': 184,\n",
       "  '1076': 185,\n",
       "  '108': 186,\n",
       "  '1088': 187,\n",
       "  '109': 188,\n",
       "  '11': 189,\n",
       "  '11.00': 190,\n",
       "  '11.15': 191,\n",
       "  '11.25': 192,\n",
       "  '11.30': 193,\n",
       "  '11.45': 194,\n",
       "  '11.50': 195,\n",
       "  '110': 196,\n",
       "  '1108': 197,\n",
       "  '111': 198,\n",
       "  '1111': 199,\n",
       "  '112': 200,\n",
       "  '113': 201,\n",
       "  '114': 202,\n",
       "  '115': 203,\n",
       "  '1155': 204,\n",
       "  '116': 205,\n",
       "  '117': 206,\n",
       "  '1178': 207,\n",
       "  '118': 208,\n",
       "  '1180': 209,\n",
       "  '12': 210,\n",
       "  '12,000': 211,\n",
       "  '12.00': 212,\n",
       "  '12.20': 213,\n",
       "  '12.25': 214,\n",
       "  '12.30': 215,\n",
       "  '12.40': 216,\n",
       "  '12.46': 217,\n",
       "  '120': 218,\n",
       "  '121,400': 219,\n",
       "  '123': 220,\n",
       "  '123,659': 221,\n",
       "  '1239': 222,\n",
       "  '125': 223,\n",
       "  '126': 224,\n",
       "  '1261': 225,\n",
       "  '127': 226,\n",
       "  '128': 227,\n",
       "  '129': 228,\n",
       "  '1299': 229,\n",
       "  '13': 230,\n",
       "  '13,000': 231,\n",
       "  '13.00': 232,\n",
       "  '13.20': 233,\n",
       "  '13.23': 234,\n",
       "  '13.25': 235,\n",
       "  '13.30': 236,\n",
       "  '13.8': 237,\n",
       "  '132': 238,\n",
       "  '134': 239,\n",
       "  '1377': 240,\n",
       "  '138': 241,\n",
       "  '139': 242,\n",
       "  '1397': 243,\n",
       "  '14': 244,\n",
       "  '14,840,000': 245,\n",
       "  '14.00': 246,\n",
       "  '14.27': 247,\n",
       "  '14.30': 248,\n",
       "  '14.40': 249,\n",
       "  '14.43': 250,\n",
       "  '14.45': 251,\n",
       "  '14.50': 252,\n",
       "  '14.51': 253,\n",
       "  '140': 254,\n",
       "  '140,000': 255,\n",
       "  '1401': 256,\n",
       "  '141': 257,\n",
       "  '142': 258,\n",
       "  '143': 259,\n",
       "  '1444': 260,\n",
       "  '145': 261,\n",
       "  '146': 262,\n",
       "  '147': 263,\n",
       "  '1485': 264,\n",
       "  '15': 265,\n",
       "  '15,000': 266,\n",
       "  '15.00': 267,\n",
       "  '15.10': 268,\n",
       "  '15.15': 269,\n",
       "  '15.20': 270,\n",
       "  '15.30': 271,\n",
       "  '15.40': 272,\n",
       "  '15.45': 273,\n",
       "  '150': 274,\n",
       "  '150,000': 275,\n",
       "  '1502': 276,\n",
       "  '1526': 277,\n",
       "  '153': 278,\n",
       "  '154': 279,\n",
       "  '155': 280,\n",
       "  '156': 281,\n",
       "  '1569': 282,\n",
       "  '157': 283,\n",
       "  '158': 284,\n",
       "  '159': 285,\n",
       "  '1599': 286,\n",
       "  '16': 287,\n",
       "  '16.00': 288,\n",
       "  '16.15': 289,\n",
       "  '16.30': 290,\n",
       "  '16.45': 291,\n",
       "  '160': 292,\n",
       "  '1607': 293,\n",
       "  '161': 294,\n",
       "  '1615': 295,\n",
       "  '1622': 296,\n",
       "  '1631': 297,\n",
       "  '165': 298,\n",
       "  '1661': 299,\n",
       "  '1662': 300,\n",
       "  '1669': 301,\n",
       "  '167': 302,\n",
       "  '168': 303,\n",
       "  '1686': 304,\n",
       "  '17': 305,\n",
       "  '17,000': 306,\n",
       "  '17.00': 307,\n",
       "  '17.10': 308,\n",
       "  '17.30': 309,\n",
       "  '17.37': 310,\n",
       "  '17.58': 311,\n",
       "  '170': 312,\n",
       "  '171': 313,\n",
       "  '172': 314,\n",
       "  '1728': 315,\n",
       "  '174': 316,\n",
       "  '175': 317,\n",
       "  '177': 318,\n",
       "  '178': 319,\n",
       "  '179': 320,\n",
       "  '1794': 321,\n",
       "  '18': 322,\n",
       "  '18.00': 323,\n",
       "  '18.10': 324,\n",
       "  '18.12': 325,\n",
       "  '18.15': 326,\n",
       "  '18.20': 327,\n",
       "  '18.30': 328,\n",
       "  '18.45': 329,\n",
       "  '18.60': 330,\n",
       "  '180': 331,\n",
       "  '181': 332,\n",
       "  '1826': 333,\n",
       "  '184': 334,\n",
       "  '1843': 335,\n",
       "  '185': 336,\n",
       "  '1869': 337,\n",
       "  '187': 338,\n",
       "  '189': 339,\n",
       "  '1893': 340,\n",
       "  '19': 341,\n",
       "  '19,600': 342,\n",
       "  '19.00': 343,\n",
       "  '19.19': 344,\n",
       "  '19.20': 345,\n",
       "  '19.25': 346,\n",
       "  '19.30': 347,\n",
       "  '19.35': 348,\n",
       "  '19.40': 349,\n",
       "  '19.50': 350,\n",
       "  '190': 351,\n",
       "  '190,000': 352,\n",
       "  '1909': 353,\n",
       "  '191': 354,\n",
       "  '192': 355,\n",
       "  '1922': 356,\n",
       "  '193': 357,\n",
       "  '1930': 358,\n",
       "  '194': 359,\n",
       "  '1943': 360,\n",
       "  '195': 361,\n",
       "  '197': 362,\n",
       "  '1981': 363,\n",
       "  '2': 364,\n",
       "  '2,000': 365,\n",
       "  '2,164,000': 366,\n",
       "  '2,400': 367,\n",
       "  '2,448': 368,\n",
       "  '2.': 369,\n",
       "  '2.1': 370,\n",
       "  '2.3': 371,\n",
       "  '2.5': 372,\n",
       "  '20': 373,\n",
       "  '20,000': 374,\n",
       "  '20.': 375,\n",
       "  '20.00': 376,\n",
       "  '20.15': 377,\n",
       "  '20.25': 378,\n",
       "  '20.3': 379,\n",
       "  '20.30': 380,\n",
       "  '20.40': 381,\n",
       "  '20.50': 382,\n",
       "  '200': 383,\n",
       "  '200,000': 384,\n",
       "  '2003': 385,\n",
       "  '2008': 386,\n",
       "  '201': 387,\n",
       "  '202': 388,\n",
       "  '2022': 389,\n",
       "  '204': 390,\n",
       "  '205': 391,\n",
       "  '207': 392,\n",
       "  '2081': 393,\n",
       "  '209': 394,\n",
       "  '2095': 395,\n",
       "  '21': 396,\n",
       "  '21.00': 397,\n",
       "  '21.09': 398,\n",
       "  '21.20': 399,\n",
       "  '21.26': 400,\n",
       "  '21.30': 401,\n",
       "  '21.40': 402,\n",
       "  '21.45': 403,\n",
       "  '21.46': 404,\n",
       "  '210': 405,\n",
       "  '211': 406,\n",
       "  '2116': 407,\n",
       "  '2135': 408,\n",
       "  '214': 409,\n",
       "  '216': 410,\n",
       "  '2165': 411,\n",
       "  '217': 412,\n",
       "  '218': 413,\n",
       "  '219': 414,\n",
       "  '2197': 415,\n",
       "  '22': 416,\n",
       "  '22.00': 417,\n",
       "  '22.30': 418,\n",
       "  '22.35': 419,\n",
       "  '22.45': 420,\n",
       "  '22.58': 421,\n",
       "  '220': 422,\n",
       "  '221': 423,\n",
       "  '222': 424,\n",
       "  '224': 425,\n",
       "  '2241': 426,\n",
       "  '225': 427,\n",
       "  '226': 428,\n",
       "  '2268': 429,\n",
       "  '227': 430,\n",
       "  '2272': 431,\n",
       "  '2288': 432,\n",
       "  '2293': 433,\n",
       "  '23': 434,\n",
       "  '23.00': 435,\n",
       "  '23.14': 436,\n",
       "  '23.20': 437,\n",
       "  '23.30': 438,\n",
       "  '23.40': 439,\n",
       "  '23.50': 440,\n",
       "  '23.55': 441,\n",
       "  '230': 442,\n",
       "  '2305': 443,\n",
       "  '233': 444,\n",
       "  '234': 445,\n",
       "  '2345': 446,\n",
       "  '236': 447,\n",
       "  '2361': 448,\n",
       "  '237': 449,\n",
       "  '2383': 450,\n",
       "  '2384': 451,\n",
       "  '24': 452,\n",
       "  '24,': 453,\n",
       "  '240': 454,\n",
       "  '2401': 455,\n",
       "  '2405': 456,\n",
       "  '244': 457,\n",
       "  '2443': 458,\n",
       "  '245': 459,\n",
       "  '2452': 460,\n",
       "  '247': 461,\n",
       "  '248': 462,\n",
       "  '249': 463,\n",
       "  '25': 464,\n",
       "  '25,000': 465,\n",
       "  '250': 466,\n",
       "  '2516': 467,\n",
       "  '2522': 468,\n",
       "  '2531': 469,\n",
       "  '2534': 470,\n",
       "  '2537': 471,\n",
       "  '2540': 472,\n",
       "  '2541': 473,\n",
       "  '2546': 474,\n",
       "  '2547': 475,\n",
       "  '2548': 476,\n",
       "  '2549': 477,\n",
       "  '2550': 478,\n",
       "  '2552': 479,\n",
       "  '2553': 480,\n",
       "  '2554': 481,\n",
       "  '2555': 482,\n",
       "  '2556': 483,\n",
       "  '2557': 484,\n",
       "  '2558': 485,\n",
       "  '2559': 486,\n",
       "  '256': 487,\n",
       "  '256.4': 488,\n",
       "  '2560': 489,\n",
       "  '2561': 490,\n",
       "  '2562': 491,\n",
       "  '2563': 492,\n",
       "  '2564': 493,\n",
       "  '2564,': 494,\n",
       "  '2565': 495,\n",
       "  '2572': 496,\n",
       "  '259': 497,\n",
       "  '2592': 498,\n",
       "  '26': 499,\n",
       "  '2608': 500,\n",
       "  '261': 501,\n",
       "  '2621': 502,\n",
       "  '265': 503,\n",
       "  '2665': 504,\n",
       "  '267': 505,\n",
       "  '2671': 506,\n",
       "  '268': 507,\n",
       "  '27': 508,\n",
       "  '270': 509,\n",
       "  '2718': 510,\n",
       "  '272': 511,\n",
       "  '27449': 512,\n",
       "  '2748': 513,\n",
       "  '2750': 514,\n",
       "  '278': 515,\n",
       "  '28': 516,\n",
       "  '28,000': 517,\n",
       "  '281': 518,\n",
       "  '2836': 519,\n",
       "  '2838': 520,\n",
       "  '2858': 521,\n",
       "  '286,000': 522,\n",
       "  '2863': 523,\n",
       "  '288': 524,\n",
       "  '289': 525,\n",
       "  '29': 526,\n",
       "  '293': 527,\n",
       "  '2942': 528,\n",
       "  '295': 529,\n",
       "  '2951': 530,\n",
       "  '2968': 531,\n",
       "  '2988': 532,\n",
       "  '299': 533,\n",
       "  '3': 534,\n",
       "  '3,': 535,\n",
       "  '3,000': 536,\n",
       "  '3,500': 537,\n",
       "  '3,600,000': 538,\n",
       "  '3,634': 539,\n",
       "  '3,950': 540,\n",
       "  '3.': 541,\n",
       "  '3.1': 542,\n",
       "  '30': 543,\n",
       "  '30,000': 544,\n",
       "  '300': 545,\n",
       "  '300,000': 546,\n",
       "  '3025': 547,\n",
       "  '303': 548,\n",
       "  '304': 549,\n",
       "  '3044': 550,\n",
       "  '308': 551,\n",
       "  '309': 552,\n",
       "  '3096': 553,\n",
       "  '31': 554,\n",
       "  '31.2': 555,\n",
       "  '3102': 556,\n",
       "  '3105': 557,\n",
       "  '3111': 558,\n",
       "  '312': 559,\n",
       "  '3126': 560,\n",
       "  '314': 561,\n",
       "  '3141': 562,\n",
       "  '315': 563,\n",
       "  '3152': 564,\n",
       "  '3154': 565,\n",
       "  '317': 566,\n",
       "  '3188': 567,\n",
       "  '319': 568,\n",
       "  '3193': 569,\n",
       "  '32': 570,\n",
       "  '320': 571,\n",
       "  '3201': 572,\n",
       "  '321': 573,\n",
       "  '323': 574,\n",
       "  '3233': 575,\n",
       "  '3234': 576,\n",
       "  '3245': 577,\n",
       "  '325': 578,\n",
       "  '327': 579,\n",
       "  '3274': 580,\n",
       "  '328': 581,\n",
       "  '33': 582,\n",
       "  '3308': 583,\n",
       "  '332': 584,\n",
       "  '335': 585,\n",
       "  '3383': 586,\n",
       "  '34': 587,\n",
       "  '34,600': 588,\n",
       "  '340': 589,\n",
       "  '341': 590,\n",
       "  '342': 591,\n",
       "  '3423': 592,\n",
       "  '3428': 593,\n",
       "  '343': 594,\n",
       "  '3464': 595,\n",
       "  '3465': 596,\n",
       "  '347': 597,\n",
       "  '3481': 598,\n",
       "  '35': 599,\n",
       "  '3504': 600,\n",
       "  '3511': 601,\n",
       "  '352': 602,\n",
       "  '352,000': 603,\n",
       "  '353': 604,\n",
       "  '3536': 605,\n",
       "  '356': 606,\n",
       "  '357': 607,\n",
       "  '358': 608,\n",
       "  '36': 609,\n",
       "  '360': 610,\n",
       "  '361': 611,\n",
       "  '3623': 612,\n",
       "  '3645': 613,\n",
       "  '365': 614,\n",
       "  '3678': 615,\n",
       "  '37': 616,\n",
       "  '37.48': 617,\n",
       "  '371': 618,\n",
       "  '374': 619,\n",
       "  '3753': 620,\n",
       "  '3799': 621,\n",
       "  '38': 622,\n",
       "  '380': 623,\n",
       "  '382': 624,\n",
       "  '3839': 625,\n",
       "  '384': 626,\n",
       "  '388': 627,\n",
       "  '3889': 628,\n",
       "  '39': 629,\n",
       "  '391': 630,\n",
       "  '396': 631,\n",
       "  '3972': 632,\n",
       "  '4': 633,\n",
       "  '4,000': 634,\n",
       "  '4,254': 635,\n",
       "  '4.': 636,\n",
       "  '4.4': 637,\n",
       "  '4.5': 638,\n",
       "  '40': 639,\n",
       "  '40,000': 640,\n",
       "  '400': 641,\n",
       "  '400,000': 642,\n",
       "  '401': 643,\n",
       "  '40200': 644,\n",
       "  '4041': 645,\n",
       "  '406': 646,\n",
       "  '4061': 647,\n",
       "  '41': 648,\n",
       "  '414': 649,\n",
       "  '4176': 650,\n",
       "  '42': 651,\n",
       "  '4220': 652,\n",
       "  '423': 653,\n",
       "  '4233': 654,\n",
       "  '424': 655,\n",
       "  '4245': 656,\n",
       "  '426': 657,\n",
       "  '4269': 658,\n",
       "  '43': 659,\n",
       "  '430': 660,\n",
       "  '4324': 661,\n",
       "  '433': 662,\n",
       "  '4331': 663,\n",
       "  '434': 664,\n",
       "  '438,000': 665,\n",
       "  '4398': 666,\n",
       "  '44': 667,\n",
       "  '4407': 668,\n",
       "  '4430': 669,\n",
       "  '444': 670,\n",
       "  '4446': 671,\n",
       "  '445': 672,\n",
       "  '4457': 673,\n",
       "  '4473': 674,\n",
       "  '45': 675,\n",
       "  '4510': 676,\n",
       "  '454': 677,\n",
       "  '4540': 678,\n",
       "  '4546': 679,\n",
       "  '456': 680,\n",
       "  '4576': 681,\n",
       "  '458': 682,\n",
       "  '46': 683,\n",
       "  '4621': 684,\n",
       "  '4649': 685,\n",
       "  '4671': 686,\n",
       "  '4682': 687,\n",
       "  '47': 688,\n",
       "  '472': 689,\n",
       "  '476': 690,\n",
       "  '4793': 691,\n",
       "  '48': 692,\n",
       "  '4841': 693,\n",
       "  '4851': 694,\n",
       "  '486': 695,\n",
       "  '4890': 696,\n",
       "  '49': 697,\n",
       "  '4903': 698,\n",
       "  '493': 699,\n",
       "  '4946': 700,\n",
       "  '496': 701,\n",
       "  '4982': 702,\n",
       "  '5': 703,\n",
       "  '5,': 704,\n",
       "  '5,000': 705,\n",
       "  '5,000,000': 706,\n",
       "  '5,800': 707,\n",
       "  '5.': 708,\n",
       "  '5.56': 709,\n",
       "  '50': 710,\n",
       "  '50,000': 711,\n",
       "  '50,290': 712,\n",
       "  '500': 713,\n",
       "  '500,000': 714,\n",
       "  '5008': 715,\n",
       "  '501': 716,\n",
       "  '5018': 717,\n",
       "  '5059': 718,\n",
       "  '5071': 719,\n",
       "  '5075': 720,\n",
       "  '5081': 721,\n",
       "  '5082': 722,\n",
       "  '51': 723,\n",
       "  '5134': 724,\n",
       "  '5156': 725,\n",
       "  '52': 726,\n",
       "  '523': 727,\n",
       "  '5230': 728,\n",
       "  '53': 729,\n",
       "  '530': 730,\n",
       "  '535': 731,\n",
       "  '5350': 732,\n",
       "  '5351': 733,\n",
       "  '5364': 734,\n",
       "  '54': 735,\n",
       "  '540': 736,\n",
       "  '5448': 737,\n",
       "  '545': 738,\n",
       "  '5465': 739,\n",
       "  '5471': 740,\n",
       "  '549': 741,\n",
       "  '55': 742,\n",
       "  '551': 743,\n",
       "  '5575': 744,\n",
       "  '5599': 745,\n",
       "  '56': 746,\n",
       "  '560': 747,\n",
       "  '5610': 748,\n",
       "  '562': 749,\n",
       "  '5663': 750,\n",
       "  '568': 751,\n",
       "  '57': 752,\n",
       "  '5766': 753,\n",
       "  '5777': 754,\n",
       "  '579': 755,\n",
       "  '5791': 756,\n",
       "  '58': 757,\n",
       "  '5849': 758,\n",
       "  '5864': 759,\n",
       "  '5873': 760,\n",
       "  '59': 761,\n",
       "  '594': 762,\n",
       "  '595': 763,\n",
       "  '595,000': 764,\n",
       "  '596': 765,\n",
       "  '5980': 766,\n",
       "  '6': 767,\n",
       "  '6,000': 768,\n",
       "  '6,000,000': 769,\n",
       "  '6,030,000': 770,\n",
       "  '6,093': 771,\n",
       "  '6,500': 772,\n",
       "  '6.': 773,\n",
       "  '6.30': 774,\n",
       "  '6.6': 775,\n",
       "  '60': 776,\n",
       "  '600': 777,\n",
       "  '600,000': 778,\n",
       "  '6016': 779,\n",
       "  '6024': 780,\n",
       "  '607': 781,\n",
       "  '6090': 782,\n",
       "  '61': 783,\n",
       "  '6108': 784,\n",
       "  '62': 785,\n",
       "  '6207': 786,\n",
       "  '6213': 787,\n",
       "  '6248': 788,\n",
       "  '6249': 789,\n",
       "  '63': 790,\n",
       "  '6316': 791,\n",
       "  '6339': 792,\n",
       "  '636,000': 793,\n",
       "  '6383': 794,\n",
       "  '6390': 795,\n",
       "  '64': 796,\n",
       "  '64,000': 797,\n",
       "  '6400': 798,\n",
       "  '641': 799,\n",
       "  '6441': 800,\n",
       "  '6458': 801,\n",
       "  '6471': 802,\n",
       "  '648': 803,\n",
       "  '65': 804,\n",
       "  '6521': 805,\n",
       "  '6530': 806,\n",
       "  '6542': 807,\n",
       "  '656': 808,\n",
       "  '6577': 809,\n",
       "  '66': 810,\n",
       "  '6644': 811,\n",
       "  '67': 812,\n",
       "  '6727': 813,\n",
       "  '6759': 814,\n",
       "  '6774': 815,\n",
       "  '679': 816,\n",
       "  '6795': 817,\n",
       "  '6797': 818,\n",
       "  '68': 819,\n",
       "  '6829': 820,\n",
       "  '6841': 821,\n",
       "  '6873': 822,\n",
       "  '6886': 823,\n",
       "  '689': 824,\n",
       "  '69': 825,\n",
       "  '690': 826,\n",
       "  '6971': 827,\n",
       "  '7': 828,\n",
       "  '7,': 829,\n",
       "  '7,000': 830,\n",
       "  '7.': 831,\n",
       "  '7.00': 832,\n",
       "  '7.15': 833,\n",
       "  '7.62': 834,\n",
       "  '7.65': 835,\n",
       "  '70': 836,\n",
       "  '700': 837,\n",
       "  '7021': 838,\n",
       "  '704': 839,\n",
       "  '707': 840,\n",
       "  '7082': 841,\n",
       "  '71': 842,\n",
       "  '710': 843,\n",
       "  '711': 844,\n",
       "  '7153': 845,\n",
       "  '7175': 846,\n",
       "  '72': 847,\n",
       "  '7221': 848,\n",
       "  '725': 849,\n",
       "  '7254': 850,\n",
       "  '73': 851,\n",
       "  '7307': 852,\n",
       "  '731': 853,\n",
       "  '7310': 854,\n",
       "  '7347': 855,\n",
       "  '7381': 856,\n",
       "  '7387': 857,\n",
       "  '7396': 858,\n",
       "  '74': 859,\n",
       "  '7412': 860,\n",
       "  '7425': 861,\n",
       "  '7431': 862,\n",
       "  '747': 863,\n",
       "  '7488': 864,\n",
       "  '7497': 865,\n",
       "  '75': 866,\n",
       "  '750': 867,\n",
       "  '7555': 868,\n",
       "  '7558': 869,\n",
       "  '7579': 870,\n",
       "  '76': 871,\n",
       "  '7614': 872,\n",
       "  '77': 873,\n",
       "  '7735': 874,\n",
       "  '7753': 875,\n",
       "  '7777': 876,\n",
       "  '7786': 877,\n",
       "  '78': 878,\n",
       "  '7847': 879,\n",
       "  '789': 880,\n",
       "  '789.': 881,\n",
       "  '7892': 882,\n",
       "  '79': 883,\n",
       "  '7903': 884,\n",
       "  '7922': 885,\n",
       "  '7923': 886,\n",
       "  '7951': 887,\n",
       "  '797': 888,\n",
       "  '7970': 889,\n",
       "  '7979': 890,\n",
       "  '8': 891,\n",
       "  '8,000': 892,\n",
       "  '8,616,000': 893,\n",
       "  '8.': 894,\n",
       "  '8.00': 895,\n",
       "  '8.2': 896,\n",
       "  '80': 897,\n",
       "  '80,000': 898,\n",
       "  '800': 899,\n",
       "  '804': 900,\n",
       "  '806': 901,\n",
       "  '8093': 902,\n",
       "  '81': 903,\n",
       "  '8104': 904,\n",
       "  '817': 905,\n",
       "  '8172': 906,\n",
       "  '8173': 907,\n",
       "  '8177': 908,\n",
       "  '82': 909,\n",
       "  '8215': 910,\n",
       "  '8242': 911,\n",
       "  '8288': 912,\n",
       "  '8294': 913,\n",
       "  '83': 914,\n",
       "  '8327': 915,\n",
       "  '8328': 916,\n",
       "  '833': 917,\n",
       "  '8334': 918,\n",
       "  '8357': 919,\n",
       "  '8364': 920,\n",
       "  '8391': 921,\n",
       "  '84': 922,\n",
       "  '84,000': 923,\n",
       "  '8412': 924,\n",
       "  '8432': 925,\n",
       "  '8434': 926,\n",
       "  '8494': 927,\n",
       "  '8497': 928,\n",
       "  '85': 929,\n",
       "  '8542': 930,\n",
       "  '8567': 931,\n",
       "  '86': 932,\n",
       "  '860': 933,\n",
       "  '8622': 934,\n",
       "  '868': 935,\n",
       "  '87': 936,\n",
       "  '8700': 937,\n",
       "  '8785': 938,\n",
       "  '88': 939,\n",
       "  '8866': 940,\n",
       "  '8874': 941,\n",
       "  '888': 942,\n",
       "  '8888': 943,\n",
       "  '8898': 944,\n",
       "  '89': 945,\n",
       "  '8948': 946,\n",
       "  '898': 947,\n",
       "  '8980': 948,\n",
       "  '9': 949,\n",
       "  '9.': 950,\n",
       "  '9.15': 951,\n",
       "  '9.76': 952,\n",
       "  '90': 953,\n",
       "  '9035': 954,\n",
       "  '9038': 955,\n",
       "  '91': 956,\n",
       "  '9107': 957,\n",
       "  '912': 958,\n",
       "  '914': 959,\n",
       "  '915': 960,\n",
       "  '916': 961,\n",
       "  '92': 962,\n",
       "  '920': 963,\n",
       "  '9217': 964,\n",
       "  '922': 965,\n",
       "  '9233': 966,\n",
       "  '925': 967,\n",
       "  '93': 968,\n",
       "  '9310': 969,\n",
       "  '9316': 970,\n",
       "  '938': 971,\n",
       "  '94': 972,\n",
       "  '9409': 973,\n",
       "  '946': 974,\n",
       "  '9487': 975,\n",
       "  '95': 976,\n",
       "  '9512': 977,\n",
       "  '952': 978,\n",
       "  '9533': 979,\n",
       "  '9534': 980,\n",
       "  '9547': 981,\n",
       "  '96': 982,\n",
       "  '960': 983,\n",
       "  '9663': 984,\n",
       "  '97': 985,\n",
       "  '9719': 986,\n",
       "  '9746': 987,\n",
       "  '9754': 988,\n",
       "  '9793': 989,\n",
       "  '9794': 990,\n",
       "  '98': 991,\n",
       "  '9831': 992,\n",
       "  '986': 993,\n",
       "  '99': 994,\n",
       "  '9908': 995,\n",
       "  '9987': 996,\n",
       "  '999': 997,\n",
       "  '9999': 998,\n",
       "  ':': 999,\n",
       "  ...},\n",
       " 'pos2idx': {'ADVI': 0,\n",
       "  'ADVN': 1,\n",
       "  'ADVP': 2,\n",
       "  'ADVS': 3,\n",
       "  'CFQC': 4,\n",
       "  'CLTV': 5,\n",
       "  'CMTR': 6,\n",
       "  'CNIT': 7,\n",
       "  'CVBL': 8,\n",
       "  'DCNM': 9,\n",
       "  'DDAC': 10,\n",
       "  'DDAN': 11,\n",
       "  'DDAQ': 12,\n",
       "  'DDBQ': 13,\n",
       "  'DIAC': 14,\n",
       "  'DIAQ': 15,\n",
       "  'DIBQ': 16,\n",
       "  'DONM': 17,\n",
       "  'EAFF': 18,\n",
       "  'EITT': 19,\n",
       "  'FIXN': 20,\n",
       "  'FIXV': 21,\n",
       "  'JCMP': 22,\n",
       "  'JCRG': 23,\n",
       "  'JSBR': 24,\n",
       "  'NCMN': 25,\n",
       "  'NCNM': 26,\n",
       "  'NEG': 27,\n",
       "  'NLBL': 28,\n",
       "  'NPRP': 29,\n",
       "  'NTTL': 30,\n",
       "  'PDMN': 31,\n",
       "  'PNTR': 32,\n",
       "  'PPRS': 33,\n",
       "  'PREL': 34,\n",
       "  'PUNC': 35,\n",
       "  'RPRE': 36,\n",
       "  'VACT': 37,\n",
       "  'VATT': 38,\n",
       "  'VSTA': 39,\n",
       "  'XVAE': 40,\n",
       "  'XVAM': 41,\n",
       "  'XVBM': 42,\n",
       "  'XVMM': 43,\n",
       "  '<UNK>': 44,\n",
       "  '<PAD>': 45},\n",
       " 'tag2idx': {'B-COLOR': 0,\n",
       "  'B-DATE': 1,\n",
       "  'B-LOCATION': 2,\n",
       "  'B-LP': 3,\n",
       "  'B-OBJECT': 4,\n",
       "  'B-ORGANIZATION': 5,\n",
       "  'B-PERSON': 6,\n",
       "  'B-TIME': 7,\n",
       "  'B-VEHICLE': 8,\n",
       "  'B-WEAPON': 9,\n",
       "  'I-COLOR': 10,\n",
       "  'I-DATE': 11,\n",
       "  'I-LOCATION': 12,\n",
       "  'I-LP': 13,\n",
       "  'I-OBJECT': 14,\n",
       "  'I-ORGANIZATION': 15,\n",
       "  'I-PERSON': 16,\n",
       "  'I-TIME': 17,\n",
       "  'I-VEHICLE': 18,\n",
       "  'I-WEAPON': 19,\n",
       "  'O': 20,\n",
       "  '<PAD>': 21}}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(f'mapping/{}.pickle', 'wb') as dict_:\n",
    "    pickle.dump(idx2word, dict_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e4a7318b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T12:43:44.950681Z",
     "start_time": "2022-01-26T12:43:44.938805Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "mapping['max_len'] = max_len\n",
    "for i in mapping.keys():\n",
    "    with open(f'mapping/NER/{i}.pickle', 'wb') as dict_:\n",
    "        pickle.dump(mapping[i], dict_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aecd662c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
